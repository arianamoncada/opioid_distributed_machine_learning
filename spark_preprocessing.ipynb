{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time \n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drugs = pd.read_csv('arcos-ca-statewide-itemized.tsv',nrows = 1000000, sep = '\\t')\n",
    "# drugs = pd.read_csv('arcos-ca-statewide-itemized.tsv', sep = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connecting to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "import os\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages \"org.apache.hadoop:hadoop-aws:2.7.4\" pyspark-shell'\n",
    "!echo $JAVA_HOME\n",
    "sc = SparkContext.getOrCreate()\n",
    "\n",
    "# YOUR AMAZON LOGIN INFORMATION HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drugs.to_csv('./arcos-ca-statewide-sample.tsv', sep = '\\t', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drugs = pd.read_csv('./arcos-ca-statewide-sample.tsv', sep = '\\t')\n",
    "# drugs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agg Sum - CALC_BASE_WT_IN_GM, QUANTITY\n",
    "# Ingredient_Name has two options: HYDROCODONE BITARTRATE HEMIPENTAHYDRATE or OXYCODONE HYDROCHLORIDE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working on sample of Drug Dataset to make a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf,SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "#from pyspark.sql.functions import concat, col, lit, substring\n",
    "\n",
    "ss = SparkSession.builder.getOrCreate()\n",
    "\n",
    "## !!!!! Change this to the S3 Bucket !!!!!!\n",
    "# drug_rdd = sc.textFile('./arcos-ca-statewide-sample.tsv').map(lambda x: x.split('\\t'))\n",
    "drug_rdd = sc.textFile('s3://data-systems-opioid/arcos-ca-statewide-itemized.tsv',24).map(lambda x: x.split('\\t'))\n",
    "\n",
    "\n",
    "def FloatSafe(value): # In case there are non-float type to be converted.\n",
    "    try:\n",
    "        return float(value)\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "def IntegerSafe(value): # In case there are non-integer type to be converted.\n",
    "    try:\n",
    "        return int(value)\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "# To reduce size, I remove the first 15 col's which are all unusable Identifiers\n",
    "drug_rdd = drug_rdd.map(lambda x: x[16:25] + x[29:]).persist()\n",
    "\n",
    "# Columns I removed:\n",
    "# -------------------------\n",
    "# 0'REPORTER_DEA_NO',\n",
    "#  'REPORTER_BUS_ACT',\n",
    "#  'REPORTER_NAME',\n",
    "#  'REPORTER_ADDL_CO_INFO',\n",
    "#  'REPORTER_ADDRESS1',\n",
    "#  'REPORTER_ADDRESS2',\n",
    "#  'REPORTER_CITY',\n",
    "#  'REPORTER_STATE',\n",
    "#  'REPORTER_ZIP',\n",
    "#  'REPORTER_COUNTY'\n",
    "#  'BUYER_DEA_NO',\n",
    "#  'BUYER_BUS_ACT',\n",
    "#  'BUYER_NAME',\n",
    "#  'BUYER_ADDL_CO_INFO',\n",
    "#  'BUYER_ADDRESS1',\n",
    "#15'BUYER_ADDRESS2'\n",
    "\n",
    "# 25 UNIT (0.001% of rows have values)\n",
    "# 26 Action Indicator\n",
    "# 27 ORDER_FORM_NO\n",
    "# 28 CORRECTION_NO\n",
    "\n",
    "# Takes header row and makes column names\n",
    "col_names = drug_rdd.first()\n",
    "\n",
    "# Removes header col\n",
    "drug_rdd = drug_rdd.filter(lambda x: x != col_names)\n",
    "\n",
    "# Fixes variable type\n",
    "drug_rdd = drug_rdd.map(lambda x: [x[0], x[1], x[2], x[3], x[4], IntegerSafe(x[5]), x[6], x[7], FloatSafe(x[8]), FloatSafe(x[9]), IntegerSafe(x[10]), FloatSafe(x[11]), FloatSafe(x[12]), IntegerSafe(x[13]),x[14], x[15], x[16], FloatSafe(x[17]), x[18], x[19], x[20], FloatSafe(x[21])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BUYER_CITY', 'BUYER_STATE', 'BUYER_ZIP', 'BUYER_COUNTY', 'TRANSACTION_CODE', 'DRUG_CODE', 'NDC_NO', 'DRUG_NAME', 'QUANTITY', 'STRENGTH', 'TRANSACTION_DATE', 'CALC_BASE_WT_IN_GM', 'DOSAGE_UNIT', 'TRANSACTION_ID', 'Product_Name', 'Ingredient_Name', 'Measure', 'MME_Conversion_Factor', 'Combined_Labeler_Name', 'Revised_Company_Name', 'Reporter_family', 'dos_str']\n"
     ]
    }
   ],
   "source": [
    "print(col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # This cell is just for Type testing\n",
    "# row_test = drug_rdd.takeSample(1, 1)[0]\n",
    "# for i in range(len(row_test)):\n",
    "#     print(i, col_names[i], row_test[i], type(row_test[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+----------+\n",
      "|BUYER_ZIP|Year|  ZIP-YEAR|\n",
      "+---------+----+----------+\n",
      "|    93003|2007|93003-2007|\n",
      "|    92649|2006|92649-2006|\n",
      "|    92653|2006|92653-2006|\n",
      "|    92113|2006|92113-2006|\n",
      "|    92113|2006|92113-2006|\n",
      "|    91301|2007|91301-2007|\n",
      "|    92584|2007|92584-2007|\n",
      "|    93402|2012|93402-2012|\n",
      "|    93065|2012|93065-2012|\n",
      "|    95536|2011|95536-2011|\n",
      "+---------+----+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# To DataFrame\n",
    "drug_df = drug_rdd.toDF(col_names)\n",
    "\n",
    "# Set up for the ZIP-YEAR join\n",
    "drug_df = drug_df.withColumn('Year', substring('TRANSACTION_DATE', -4,4))\n",
    "drug_df = drug_df.withColumn('ZIP-YEAR', concat(col(\"BUYER_ZIP\"), lit(\"-\"), col(\"Year\")))\n",
    "drug_df.select(\"BUYER_ZIP\",\"Year\",'ZIP-YEAR').show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Suicide DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "death_rdd = sc.textFile('s3://data-systems-opioid/CA_suicides.csv',24).map(lambda x: x.split(','))\n",
    "\n",
    "# Takes header row and makes column names\n",
    "col_names = death_rdd.first()\n",
    "\n",
    "# Removes header col\n",
    "death_rdd = death_rdd.filter(lambda x: x != col_names)\n",
    "\n",
    "# Fix RDD\n",
    "death_rdd = death_rdd.map(lambda x: [x[0], x[1], x[2], IntegerSafe(x[3]), IntegerSafe(x[4])])\n",
    "\n",
    "# To SQL DataFrame\n",
    "death_df = death_rdd.toDF(col_names)\n",
    "death_df = death_df.withColumn('SUI_per_thousand', death_df['Count']/death_df['Population_2018'] * 1000)\n",
    "\n",
    "# Set Up for the ZIP-YEAR merg\n",
    "death_df = death_df.withColumn('ZIP-YEAR', concat(col(\"ZIP Code\"), lit(\"-\"), col(\"Year\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joining drug_df and death_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change this join based on what flags we add\n",
    "drug_agg_df = drug_df.groupBy('ZIP-YEAR').agg(count('BUYER_CITY'), sum('STRENGTH'), sum('QUANTITY'), sum('CALC_BASE_WT_IN_GM'), sum('dos_str'))\n",
    "# drug_agg_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------------+-------------+-------------+-----------------------+------------------+-----+--------------------+\n",
      "|  ZIP-YEAR|count(BUYER_CITY)|sum(STRENGTH)|sum(QUANTITY)|sum(CALC_BASE_WT_IN_GM)|      sum(dos_str)|Count|    SUI_per_thousand|\n",
      "+----------+-----------------+-------------+-------------+-----------------------+------------------+-----+--------------------+\n",
      "|90026-2007|              957|          0.0|       1627.0|      3555.921771999999|14153.550000000001|    0|                 0.0|\n",
      "|90031-2009|              357|        800.0|        569.0|      777.7937249999999|            3425.0|    1| 0.02557348541032657|\n",
      "|90211-2010|             3564|          0.0|      25310.0|     14238.731438450004| 55416.24900000001|    1| 0.12470382840753212|\n",
      "|90505-2010|             4571|          0.0|     105481.0|     11270.256617024996| 52662.53250000001|    7|  0.1873260543780775|\n",
      "|90815-2010|             2827|          0.0|       6643.0|         8369.819107575|        29509.8355|    6| 0.14866572511707427|\n",
      "|90815-2011|             3031|          0.0|       7338.0|      8529.590506650002|         30530.855|    4| 0.09911048341138284|\n",
      "|91303-2007|             1300|          0.0|       1875.0|     2961.9752437249977|12710.156500000001|    2| 0.06583278472679394|\n",
      "|91506-2009|             1821|          0.0|       2835.0|      3279.126340150002|        17612.3355|    3|  0.1644286105782406|\n",
      "|91602-2008|              718|          0.0|       2620.0|     2137.0134399999997|            8820.0|    1|0.052787162162162164|\n",
      "|91746-2006|              127|          0.0|        176.0|              236.78845|             937.5|    3|   0.097911227154047|\n",
      "+----------+-----------------+-------------+-------------+-----------------------+------------------+-----+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "death_join_df = death_df.select('ZIP-YEAR','Count','SUI_per_thousand')\n",
    "drug_death_df = drug_agg_df.join(death_join_df, 'ZIP-YEAR', 'left_outer')\n",
    "drug_death_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 289.8026008605957 seconds ---\n"
     ]
    }
   ],
   "source": [
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
